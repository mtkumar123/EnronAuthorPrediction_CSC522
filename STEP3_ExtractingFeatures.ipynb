{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fea5e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/manoj/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/manoj/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import copy\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ca6a79",
   "metadata": {},
   "source": [
    "Using the enron.csv file created in the previous notebook ,\n",
    "we are extracting the emails of only top 5,10,15 authors(sorted according to no of emails per author) for our analysis \n",
    "and dropping any mails that have no text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ef30eef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put in the file path to the dataset created from extractingauthors.ipynb\n",
    "df = pd.read_csv(\"./enron.csv\")\n",
    "df = df.drop([\"Email Folder\"], axis=1)\n",
    "#We need only the top 20 authors ordered by number of emails found in either the\n",
    "#sent folder or _sent_mail folder\n",
    "\n",
    "#Add top_authors = df.value_counts([\"Folder\"])[:X] for the number of authors required\n",
    "# Change X to 5,10,15 to test with 5, 10, 15 authors\n",
    "top_authors = df.value_counts([\"Folder\"])[:5]\n",
    "df = df.loc[df[\"Folder\"].isin(list(top_authors.index.get_level_values(0)))].drop([\"Unnamed: 0\"], axis=1).reset_index(drop=True)\n",
    "df = df[df[\"Text\"]!=\" \"]\n",
    "df = df[df[\"Text\"]!=\"\\n\"]\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4eaa67ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mann-k          8167\n",
       "kaminski-v      5926\n",
       "dasovich-j      4805\n",
       "germany-c       4571\n",
       "shackleton-s    4003\n",
       "Name: Folder, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Folder\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077d6380",
   "metadata": {},
   "source": [
    "Random Sampling equal number of emails from each author "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c6105b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_distribution(samples_per_author, df):\n",
    "    df3 = pd.DataFrame(columns=[\"Author\", \"Folder\", \"File\", \"Text\", \"Raw Text\"]) \n",
    "    for folder in df[\"Folder\"].value_counts().index:\n",
    "        df3 = df3.append(df[df[\"Folder\"]==folder].sample(n=samples_per_author), ignore_index=True)\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d7769d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mann-k          4000\n",
      "kaminski-v      4000\n",
      "dasovich-j      4000\n",
      "germany-c       4000\n",
      "shackleton-s    4000\n",
      "Name: Folder, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Folder</th>\n",
       "      <th>File</th>\n",
       "      <th>Text</th>\n",
       "      <th>Raw Text</th>\n",
       "      <th>Message ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kay</td>\n",
       "      <td>mann-k</td>\n",
       "      <td>540.0</td>\n",
       "      <td>Thanks thanks thanks\\n\\n</td>\n",
       "      <td>Message-ID: &lt;21864199.1075846041637.JavaMail.e...</td>\n",
       "      <td>21864199.1075846041637.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kay</td>\n",
       "      <td>mann-k</td>\n",
       "      <td>3623.0</td>\n",
       "      <td>I heard a rumor that there is a new leader for...</td>\n",
       "      <td>Message-ID: &lt;237189.1075846007044.JavaMail.eva...</td>\n",
       "      <td>237189.1075846007044.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kay</td>\n",
       "      <td>mann-k</td>\n",
       "      <td>2175.0</td>\n",
       "      <td>I won't do anything about this until you reach...</td>\n",
       "      <td>Message-ID: &lt;19081360.1075846081129.JavaMail.e...</td>\n",
       "      <td>19081360.1075846081129.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kay</td>\n",
       "      <td>mann-k</td>\n",
       "      <td>513.0</td>\n",
       "      <td>Heather,\\n\\nDid you want to send this?  Anythi...</td>\n",
       "      <td>Message-ID: &lt;29170173.1075845930936.JavaMail.e...</td>\n",
       "      <td>29170173.1075845930936.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kay</td>\n",
       "      <td>mann-k</td>\n",
       "      <td>3263.0</td>\n",
       "      <td>FYI.\\n</td>\n",
       "      <td>Message-ID: &lt;9690619.1075846108468.JavaMail.ev...</td>\n",
       "      <td>9690619.1075846108468.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>Sara</td>\n",
       "      <td>shackleton-s</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>per my voice mail\\n</td>\n",
       "      <td>Message-ID: &lt;8208851.1075844556442.JavaMail.ev...</td>\n",
       "      <td>8208851.1075844556442.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>Sara</td>\n",
       "      <td>shackleton-s</td>\n",
       "      <td>812.0</td>\n",
       "      <td>Would someone please provide me with an explan...</td>\n",
       "      <td>Message-ID: &lt;30780824.1075844536582.JavaMail.e...</td>\n",
       "      <td>30780824.1075844536582.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>Sara</td>\n",
       "      <td>shackleton-s</td>\n",
       "      <td>5506.0</td>\n",
       "      <td>Please schedule 30 minutes with Laurel to disc...</td>\n",
       "      <td>Message-ID: &lt;22516364.1075844908943.JavaMail.e...</td>\n",
       "      <td>22516364.1075844908943.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>Sara</td>\n",
       "      <td>shackleton-s</td>\n",
       "      <td>2077.0</td>\n",
       "      <td>Thanks for the catch!  Sara\\n</td>\n",
       "      <td>Message-ID: &lt;1832774.1075844568746.JavaMail.ev...</td>\n",
       "      <td>1832774.1075844568746.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>Shackleton, Sara</td>\n",
       "      <td>shackleton-s</td>\n",
       "      <td>139.0</td>\n",
       "      <td>Ed:\\n\\nI received a message from the lawyer fo...</td>\n",
       "      <td>Message-ID: &lt;13713524.1075858808890.JavaMail.e...</td>\n",
       "      <td>13713524.1075858808890.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Author        Folder    File  \\\n",
       "0                   Kay        mann-k   540.0   \n",
       "1                   Kay        mann-k  3623.0   \n",
       "2                   Kay        mann-k  2175.0   \n",
       "3                   Kay        mann-k   513.0   \n",
       "4                   Kay        mann-k  3263.0   \n",
       "...                 ...           ...     ...   \n",
       "19995              Sara  shackleton-s  1587.0   \n",
       "19996              Sara  shackleton-s   812.0   \n",
       "19997              Sara  shackleton-s  5506.0   \n",
       "19998              Sara  shackleton-s  2077.0   \n",
       "19999  Shackleton, Sara  shackleton-s   139.0   \n",
       "\n",
       "                                                    Text  \\\n",
       "0                               Thanks thanks thanks\\n\\n   \n",
       "1      I heard a rumor that there is a new leader for...   \n",
       "2      I won't do anything about this until you reach...   \n",
       "3      Heather,\\n\\nDid you want to send this?  Anythi...   \n",
       "4                                                 FYI.\\n   \n",
       "...                                                  ...   \n",
       "19995                                per my voice mail\\n   \n",
       "19996  Would someone please provide me with an explan...   \n",
       "19997  Please schedule 30 minutes with Laurel to disc...   \n",
       "19998                      Thanks for the catch!  Sara\\n   \n",
       "19999  Ed:\\n\\nI received a message from the lawyer fo...   \n",
       "\n",
       "                                                Raw Text  \\\n",
       "0      Message-ID: <21864199.1075846041637.JavaMail.e...   \n",
       "1      Message-ID: <237189.1075846007044.JavaMail.eva...   \n",
       "2      Message-ID: <19081360.1075846081129.JavaMail.e...   \n",
       "3      Message-ID: <29170173.1075845930936.JavaMail.e...   \n",
       "4      Message-ID: <9690619.1075846108468.JavaMail.ev...   \n",
       "...                                                  ...   \n",
       "19995  Message-ID: <8208851.1075844556442.JavaMail.ev...   \n",
       "19996  Message-ID: <30780824.1075844536582.JavaMail.e...   \n",
       "19997  Message-ID: <22516364.1075844908943.JavaMail.e...   \n",
       "19998  Message-ID: <1832774.1075844568746.JavaMail.ev...   \n",
       "19999  Message-ID: <13713524.1075858808890.JavaMail.e...   \n",
       "\n",
       "                    Message ID  \n",
       "0      21864199.1075846041637.  \n",
       "1        237189.1075846007044.  \n",
       "2      19081360.1075846081129.  \n",
       "3      29170173.1075845930936.  \n",
       "4       9690619.1075846108468.  \n",
       "...                        ...  \n",
       "19995   8208851.1075844556442.  \n",
       "19996  30780824.1075844536582.  \n",
       "19997  22516364.1075844908943.  \n",
       "19998   1832774.1075844568746.  \n",
       "19999  13713524.1075858808890.  \n",
       "\n",
       "[20000 rows x 6 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the number of samples per author here\n",
    "df = uniform_distribution(4000, df)\n",
    "print(df[\"Folder\"].value_counts())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2880d311",
   "metadata": {},
   "source": [
    "In the next three cells , we have written function to extract the stylometric features(a combination of lexical\n",
    ", structural and syntatic features)of a particular email using regex matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2bcdc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Extraction - Manoj\n",
    "#extract feature - email length in characters. Exclude all whitespace. \n",
    "def feature_email_length_characters(text):\n",
    "    if type(text) == str:\n",
    "        text = text.strip()\n",
    "        text = re.sub(r\"\\W\", \"\", text)\n",
    "        length = len(text)\n",
    "        return length\n",
    "    else:\n",
    "        return np.NaN\n",
    "\n",
    "#extract digit density - ratio of number of digits to number of characters\n",
    "def feature_digit_density(text):\n",
    "    if type(text) == str:\n",
    "        text = text.strip()\n",
    "        text = re.sub(r\"\\W\", \"\", text)\n",
    "        total_length = len(text)\n",
    "        number_digits = len(re.findall(r\"\\d\", text))\n",
    "        try:\n",
    "            return (number_digits/total_length)\n",
    "        except ZeroDivisionError as e:\n",
    "            return 0\n",
    "    if type(text) == float:\n",
    "        return np.NaN\n",
    "\n",
    "#extract space density - ratio of space to number of characters\n",
    "def feature_space_density(text):\n",
    "    if type(text) == str:\n",
    "        number_space = len(re.findall(r\"[\\s\\n\\t]\", text))\n",
    "        text = text.strip()\n",
    "        text = re.sub(r\"\\W\", \"\", text)\n",
    "        total_length = len(text)\n",
    "        try:\n",
    "            return (number_space/total_length)\n",
    "        except ZeroDivisionError as e:\n",
    "            return 0\n",
    "    if type(text) == float:\n",
    "        return np.NaN\n",
    "\n",
    "#extract number of paragraphs\n",
    "def feature_paragraph(text):\n",
    "    if type(text) == str:\n",
    "        number_paragraphs = len(re.findall(r\"\\n\\n\", text))\n",
    "        return max(1.0, number_paragraphs)\n",
    "    if type(text) == float:\n",
    "        return np.NaN\n",
    "    \n",
    "# extract number of sentences in paragraphs\n",
    "def feature_average_characters_paragraph(text):\n",
    "    if type(text) == str:\n",
    "        number_paragraphs = len(re.findall(r\"\\n\\n\", text))\n",
    "        if not number_paragraphs:\n",
    "            return max(1, len(re.findall(r\"[.?!]\\W\", text)))\n",
    "        else:\n",
    "            paragraphs = re.findall(r\"(?:.+\\n)+\\n\", text)\n",
    "            length = 0\n",
    "            for paragraph in paragraphs:\n",
    "                length += max(1, len(re.findall(r\"[.?!]\\W\", paragraph)))\n",
    "            return length/number_paragraphs\n",
    "    if type(text) == float:\n",
    "        return np.NaN\n",
    "    \n",
    "\n",
    "#extract farewell words\n",
    "def feature_farewell_words(text):\n",
    "    if type(text) == str:\n",
    "        try:\n",
    "            words = text.split()\n",
    "            for word in reversed(words):\n",
    "                if re.search(r\"\\w+\", word):\n",
    "                    last_word = re.search(r\"\\w+\", word).group().lower()\n",
    "                    return last_word\n",
    "                else:\n",
    "                    continue\n",
    "            return \"\\n\"\n",
    "        except IndexError as e:\n",
    "            return np.NaN\n",
    "    if type(text) == float:\n",
    "        return np.NaN\n",
    "\n",
    "def feature_freq_farewell_words(farewell_words, text):\n",
    "    if type(text) == str:\n",
    "        if text in farewell_words:\n",
    "            return text\n",
    "        else:\n",
    "            return \"Other\"\n",
    "    if type(text) == float:\n",
    "        return np.NaN\n",
    "        \n",
    "\n",
    "#extract last punctuation\n",
    "def feature_ending_punctuation(text):\n",
    "    if type(text) == str:\n",
    "        if re.search(r\"[\\!\\,\\.\\?\\:\\'\\\"]\", text):\n",
    "            try:\n",
    "                last_punc = re.findall(r\"[\\!\\,\\.\\?\\:\\'\\\"]\", text)[-1]\n",
    "                return last_punc\n",
    "            except IndexError as e:\n",
    "                last_punc = len(re.findall(r\"[\\!\\,\\.\\?\\:\\'\\\"]\", text))\n",
    "                if len == 1:\n",
    "                    return last_punc[0]\n",
    "        else:\n",
    "            return \"None\"\n",
    "    if type(text) == float:\n",
    "        return np.NaN\n",
    "\n",
    "#extract most common used punctuation in the email\n",
    "def feature_most_used_punctuation(text):\n",
    "    if type(text) == str:\n",
    "        if re.search(r\"[\\!\\,\\.\\?\\:\\'\\\"]\", text):\n",
    "            punc = re.findall(r\"[\\!\\,\\.\\?\\:\\'\\\"]\", text)\n",
    "            most_used_punc = Counter(punc).most_common(1)[0][0]\n",
    "            return most_used_punc\n",
    "        else:\n",
    "            return \"None\"\n",
    "    if type(text) == float:\n",
    "        return np.NaN\n",
    "    \n",
    "#extract subjectivity and polarity\n",
    "def feature_subjectivity(text):\n",
    "    if type(text) == str:\n",
    "        blob = TextBlob(text)\n",
    "        return blob.sentiment.subjectivity\n",
    "    if type(text) == float:\n",
    "        return np.NaN\n",
    "\n",
    "#extract polarity\n",
    "def feature_polarity(text):\n",
    "    if type(text) == str:\n",
    "        blob = TextBlob(text)\n",
    "        return blob.sentiment.polarity\n",
    "    if type(text) == float:\n",
    "        return np.NaN\n",
    "\n",
    "def feature_most_pos(text):\n",
    "    if type(text) == str:\n",
    "        blob = TextBlob(text)\n",
    "        final_pos = []\n",
    "        for word, pos in blob.tags:\n",
    "            if word not in stopwords.words(\"english\"):\n",
    "                final_pos.append(pos)\n",
    "        count_pos = Counter(final_pos)\n",
    "        if count_pos.most_common():\n",
    "            return count_pos.most_common()[0][0]\n",
    "        else:\n",
    "            return \"Other\"\n",
    "    if type(text) == float:\n",
    "        return np.NaN\n",
    "\n",
    "def feature_get_greeting(text):\n",
    "    if type(text) == str:\n",
    "        if re.match(r\"^\\w+\", text):\n",
    "            greeting_word = re.match(r\"^\\w+\", text).group()\n",
    "            return greeting_word\n",
    "        else:\n",
    "            return \"None\"\n",
    "    if type(text) == float:\n",
    "        return np.NaN\n",
    "\n",
    "def feature_most_common_word(text):\n",
    "    if type(text) == str:\n",
    "        blob = TextBlob(text)\n",
    "        words = []\n",
    "        for word, pos in blob.tags:\n",
    "            words.append(word)\n",
    "        count_word = Counter(words)\n",
    "        if count_word.most_common():\n",
    "            return count_word.most_common()[0][0]\n",
    "        else:\n",
    "            return np.NaN\n",
    "    if type(text) == float:\n",
    "        return np.NaN\n",
    "\n",
    "def feature_freq_most_common_word(text):\n",
    "    if type(text) == str:\n",
    "        blob = TextBlob(text)\n",
    "        words = []\n",
    "        for word, pos in blob.tags:\n",
    "            words.append(word)\n",
    "        count_word = Counter(words)\n",
    "        if count_word.most_common():\n",
    "            return count_word.most_common()[0][1]\n",
    "        else:\n",
    "            return 0\n",
    "    if type(text) == float:\n",
    "        return np.NaN\n",
    "\n",
    "def feature_number_words(text):\n",
    "    if type(text) == str:\n",
    "        blob = TextBlob(text)\n",
    "        return len(blob.words)\n",
    "    if type(text) == float:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd665502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Extraction - Sairaj\n",
    "#Average length of words\n",
    "def avg_length(text):\n",
    "    if type(text) == str:\n",
    "        list1 = text.split()\n",
    "        word_len = 0\n",
    "        for text in list1:\n",
    "            strip_text=text.strip()\n",
    "            if re.search(r\"\\w+\",strip_text):\n",
    "                strip_text = re.search(r\"\\w+\",strip_text).group()\n",
    "                word_len += len(strip_text)\n",
    "        try:\n",
    "            avg_word_len = word_len/len(list1)\n",
    "        except ZeroDivisionError as e:\n",
    "            return np.NaN\n",
    "        return avg_word_len\n",
    "    else:\n",
    "        return np.NaN\n",
    "\n",
    "#Average Sentence Length\n",
    "def avg_sentence_length(text):\n",
    "    if type(text) == str:\n",
    "        list1 = re.findall(r\"[^\\.\\?\\!]+\",text)\n",
    "        sent_len = 0 \n",
    "        for le in list1:\n",
    "            sent_len += len(le)\n",
    "        try:\n",
    "            return sent_len/len(list1) \n",
    "        except:\n",
    "            return np.NaN      \n",
    "    else:\n",
    "        return np.NaN\n",
    "\n",
    "#Number of short words to overall number of words\n",
    "def feature_short_word_ratio(text):\n",
    "    if type(text) == str:\n",
    "        list1 = text.split()\n",
    "        short_word = 0\n",
    "        if len(list1) >= 1:\n",
    "            for word in list1:\n",
    "                strip_text = word.strip()\n",
    "                if re.search(r\"\\w+\",strip_text):\n",
    "                    strip_text = re.search(r\"\\w+\",strip_text).group()\n",
    "                    word_len = len(strip_text)\n",
    "                    if word_len < 4:\n",
    "                        short_word +=1\n",
    "            try:\n",
    "                short_word_rat = short_word/len(list1)\n",
    "                return short_word_rat\n",
    "            except:\n",
    "                return 0\n",
    "        else:\n",
    "            return 0  \n",
    "    else:\n",
    "        return np.NaN\n",
    "\n",
    "#Frequency of punctuation\n",
    "def punctuation_frequency(text):\n",
    "    if type(text) == str:\n",
    "        if re.search(r\"[\\!\\,\\.\\?\\:\\'\\\"]\", text):\n",
    "            punc = re.findall(r\"[\\!\\,\\.\\?\\:\\'\\\"]\", text)\n",
    "            freq_punc = len(punc)\n",
    "            return freq_punc\n",
    "        else:\n",
    "            return 0\n",
    "    if type(text) == float:\n",
    "        return np.NaN\n",
    "\n",
    "#Punctuation after greeting\n",
    "def punctuation_greeting(text):\n",
    "    if type(text) == str:\n",
    "        if re.search(r\"^\\w+([\\,\\:\\?\\!\\-])\\n\", text):\n",
    "            punc = re.search(r\"^\\w+([\\,\\:\\?\\!\\-])\\n\", text).group(1)\n",
    "            return punc\n",
    "        else:\n",
    "            return \"None\"\n",
    "    if type(text) == float:\n",
    "        return np.NaN\n",
    "\n",
    "def feature_number_special_characters(text):\n",
    "    if type(text) == str:\n",
    "        special_characters = re.findall(r\"[\\@\\#\\$\\%\\^\\&\\~\\`\\*\\(\\)\\<\\>\\\\\\[\\]\\{\\}\\|]\", text)\n",
    "        return len(special_characters)\n",
    "    if type(text) == float:\n",
    "        return np.NaN\n",
    "\n",
    "def feature_max_special_character(text):\n",
    "    if type(text) == str:\n",
    "        special_characters = re.findall(r\"[\\@\\#\\$\\%\\^\\&\\~\\`\\*\\(\\)\\<\\>\\\\\\[\\]\\{\\}\\|]\", text)\n",
    "        special_char_count = Counter(special_characters)\n",
    "        if special_char_count.most_common():\n",
    "            max_special_char = special_char_count.most_common()[0][0]\n",
    "            return max_special_char\n",
    "        else:\n",
    "            return \"None\"\n",
    "    if type(text) == float:\n",
    "        return np.NaN\n",
    "\n",
    "def feature_freq_max_special_character(text):\n",
    "    if type(text) == str:\n",
    "        special_characters = re.findall(r\"[\\@\\#\\$\\%\\^\\&\\~\\`\\*\\(\\)\\<\\>\\\\\\[\\]\\{\\}\\|]\", text)\n",
    "        special_char_count = Counter(special_characters)\n",
    "        if special_char_count.most_common():\n",
    "            freq_max_special_char = special_char_count.most_common()[0][1]\n",
    "            return freq_max_special_char\n",
    "        else:\n",
    "            return \"0\"\n",
    "    if type(text) == float:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9cda6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Extraction - Jaydeep\n",
    "  \n",
    "def check_single_sentence(clean_text):\n",
    "    if type(clean_text) == str:\n",
    "        ending_punc = re.findall(r\"[.?!]\", clean_text)\n",
    "        ending_punc_count = Counter(ending_punc)\n",
    "        single_sentence = False\n",
    "        if(ending_punc_count):\n",
    "            max_ep_char = max(ending_punc_count, key=ending_punc_count.get)\n",
    "            max_ep_value = max(ending_punc_count.values())\n",
    "        else:\n",
    "            max_ep_char = ''\n",
    "            max_ep_value = 0\n",
    "        if max_ep_value<=1:\n",
    "            single_sentence = True\n",
    "    elif type(clean_text) == float:\n",
    "        return np.NaN \n",
    "    return single_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78956700",
   "metadata": {},
   "source": [
    "In the next few cells ,we have extracted the features for the text part of all emails in the dataset using the functions defined in the above cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "447e5c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1046\n",
       "1           8\n",
       "2        1955\n",
       "3         172\n",
       "4         400\n",
       "         ... \n",
       "53194      98\n",
       "53195      23\n",
       "53196     119\n",
       "53197     168\n",
       "53198       8\n",
       "Name: Text, Length: 52210, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_length = df[\"Text\"].apply(lambda row: feature_email_length_characters(row))\n",
    "email_length.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d51bcc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.009560\n",
       "1        0.000000\n",
       "2        0.009719\n",
       "3        0.075581\n",
       "4        0.010000\n",
       "           ...   \n",
       "53194    0.000000\n",
       "53195    0.000000\n",
       "53196    0.067227\n",
       "53197    0.005952\n",
       "53198    0.000000\n",
       "Name: Text, Length: 52210, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_density = df[\"Text\"].apply(lambda row: feature_digit_density(row))\n",
    "digit_density.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "750af738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.278203\n",
       "1        0.375000\n",
       "2        0.267519\n",
       "3        0.267442\n",
       "4        0.282500\n",
       "           ...   \n",
       "53194    0.295918\n",
       "53195    0.347826\n",
       "53196    0.310924\n",
       "53197    0.351190\n",
       "53198    0.500000\n",
       "Name: Text, Length: 52210, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space_density = df[\"Text\"].apply(lambda row: feature_space_density(row))\n",
    "space_density.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e2ff496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1.0\n",
       "1        1.0\n",
       "2        3.0\n",
       "3        1.0\n",
       "4        1.0\n",
       "        ... \n",
       "53194    1.0\n",
       "53195    1.0\n",
       "53196    1.0\n",
       "53197    1.0\n",
       "53198    1.0\n",
       "Name: Text, Length: 52210, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_paragraphs = df[\"Text\"].apply(lambda row: feature_paragraph(row))\n",
    "number_paragraphs.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72dbf833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        22.0\n",
       "1         1.0\n",
       "2        13.0\n",
       "3         3.0\n",
       "4         7.0\n",
       "         ... \n",
       "53194     2.0\n",
       "53195     2.0\n",
       "53196     2.0\n",
       "53197     7.0\n",
       "53198     1.0\n",
       "Name: Text, Length: 52210, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_sentences_paragraph = df[\"Text\"].apply(lambda row: feature_average_characters_paragraph(row))\n",
    "average_sentences_paragraph.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8a2c7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vince       3974\n",
      "kay         3019\n",
      "thanks      2425\n",
      "sara        1570\n",
      "kate        1445\n",
      "            ... \n",
      "3300           1\n",
      "90011682       1\n",
      "bases          1\n",
      "tossed         1\n",
      "splits         1\n",
      "Name: Text, Length: 5284, dtype: int64\n",
      "['vince', 'kay', 'thanks', 'sara', 'kate', 'jeff', 'sally', 'best', 'you', '713', 'pl', 'fyi', 'it', 'me', 'fax', 'http', 'ss', 'this', 'know', 'the', '853', 'ckm', 'today', 'susan', 'to', 'questions', 'help', 'eric', 'that', 'kaminski', 'e', 'now', 'week', 'mark', 'there', 'time', 'tomorrow', 'out', 'in', 'john', 'soon', 'is', 'up', 'call', '\\n', 'one', 'tonight', 'think', 'on', 'day', 'i', 'weekend', 'done', 'them', 'a', 'again', 'well', 'yet', '3', 'list', 'yes', 'ok', 'do', 'good', 'comments', 'night', 'of', 'work', 'am', 'agreement', 'and', 'too', 'for', '2', 'go', 'here', 'sue', 'love', '4', 'below', 'pm', 'deal', 'be', '20', 'though', 'please', 'meeting', 'later', 'monday', 'much', 'us', 'attached', '1', 'changed', 'morning', 'back', 'will', 'with', 'email', 'right', 'year', '10', 'have', 'not', 'draft', 'about', 'him', 'going', 'friday', 'matter', '503', 'can', 'then', 'x39106', 'services', 'game', 'afternoon', 'correct', 'fun', 'are', '7', 'problem', 'sorry', 'file', 'so', 'no', '5', 'counterparty', 'stuff', 'review', 'at', 'number', 'contract', 'attend', 'group', '415', 'name', 'deserved', 'changes', 'deals', 'her', 'home', 'office', 'we', 'change', 'fine', 'discuss', 'lunch', 'man', 'issues', 'way', 'address', 'version', 'enron', 'great', 'beck', 'info', 'days', 'off', 'credit', 'something', 'place', '646', 'desk', '11', 'sure', 'these', 'dp', '8', 'advise', 'funny', 'form', 'possible', 'want', 'anyway', 'assistance', 'party', 'chance', 'or', 'luck', 'available', 'date', 'report', 'mail', 'all', 'information', 'your', 'approved', 'etc', 'website', 'else', 'request', 'thing', 'also', 'wednesday', 'job', 'thx', 'anything', 'team', 'k', 'my', 'system', '12', 'trip', 'contracts', 'what', 'better', 'power', 'patti', '6', 'company', 'message', 'calendar', 'test', 'requested', 'people', 'gas', 'houston', 'works', 'taylor', 'month', '2001', 'yesterday', 'update', 'follow', 'same', 'nice', 'dinner', 'mind', '2000', 'point', 'see', 'asap', 'posted', 'master', 'shortly', 'copy', 'come', 'care', 'schedule', 'o', 'more', 'from', 'like', 'scott', 'sat', 'look', 'issue', 'together', 'numbers', 'tuesday', 'attachment', 'approval', 'phone', 'doing', 'access', 'helpful', 'agreements', 'interested', 'yep', 'guys', 'notice', 'need', 'print', 'details', '9', 'town', 'first', 'money', 'x3', 'thursday', 'ditto', 'only', 'support', 'down', 'products', 'legal', 'don', 'letter', 'trading', 'get', 'either', 'ena', 'our', 'over', 'worksheet', 'debra', 'business', 'lot', 'huh', 'before', 'vacation', 's', 'play', 'thoughts', 'problems', 'nope', 'years', 'bass', 'wicek', 'inc', 'signed', 'idea', 'agree', 'vkamins']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0          Other\n",
       "1            you\n",
       "2          Other\n",
       "3         thanks\n",
       "4          Other\n",
       "          ...   \n",
       "53194    morning\n",
       "53195       good\n",
       "53196         10\n",
       "53197      Other\n",
       "53198      Other\n",
       "Name: Text, Length: 52210, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "farewell_words = df[\"Text\"].apply(lambda row: feature_farewell_words(row))\n",
    "raw_freq_farewell_words = farewell_words.value_counts()\n",
    "print(raw_freq_farewell_words)\n",
    "raw_freq_farewell_words = list(raw_freq_farewell_words[raw_freq_farewell_words>20].index)\n",
    "print(raw_freq_farewell_words)\n",
    "freq_farewell_words = []\n",
    "for word in raw_freq_farewell_words:\n",
    "    tokens = nlp(word)\n",
    "    for token in tokens:\n",
    "        if token.pos_ not in [\"PROPN\"]:\n",
    "            freq_farewell_words.append(token.text)\n",
    "\n",
    "farewell_words = farewell_words.apply(lambda row: feature_freq_farewell_words(freq_farewell_words, row))\n",
    "farewell_words.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e0567c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             Hey\n",
       "1           Thank\n",
       "2               a\n",
       "3           Frank\n",
       "4             don\n",
       "           ...   \n",
       "53194         are\n",
       "53195    whatever\n",
       "53196          we\n",
       "53197           i\n",
       "53198        lisa\n",
       "Name: Text, Length: 52210, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greeting_words = df[\"Text\"].apply(lambda row: feature_get_greeting(row))\n",
    "greeting_words.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8401eca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             the\n",
       "1           Thank\n",
       "2             the\n",
       "3             the\n",
       "4              to\n",
       "           ...   \n",
       "53194         you\n",
       "53195    whatever\n",
       "53196          at\n",
       "53197           i\n",
       "53198        lisa\n",
       "Name: Text, Length: 52083, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_word = df[\"Text\"].apply(lambda row: feature_most_common_word(row))\n",
    "most_common_word.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "146de04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Author                                                     John\n",
       "Folder                                                 arnold-j\n",
       "File                                                       57.0\n",
       "Message ID                              12437191.1075852711582.\n",
       "Text          your guys are probably seeing this as well, bu...\n",
       "Raw Text      Message-ID: <12437191.1075852711582.JavaMail.e...\n",
       "Name: 1732, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_word[most_common_word.isna()==True]\n",
    "df.iloc[1714]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f121dd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0.493526\n",
      "1        0.000000\n",
      "2        0.423773\n",
      "3        0.100000\n",
      "4        0.402626\n",
      "           ...   \n",
      "53194    0.000000\n",
      "53195    0.600000\n",
      "53196    0.000000\n",
      "53197    0.506944\n",
      "53198    0.000000\n",
      "Name: Text, Length: 52210, dtype: float64\n",
      "0        0.135994\n",
      "1        0.000000\n",
      "2        0.019855\n",
      "3        0.066667\n",
      "4       -0.008687\n",
      "           ...   \n",
      "53194    0.000000\n",
      "53195    0.700000\n",
      "53196    0.000000\n",
      "53197    0.198611\n",
      "53198    0.000000\n",
      "Name: Text, Length: 52210, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "subjectivity = df[\"Text\"].apply(lambda row: feature_subjectivity(row))\n",
    "polarity = df[\"Text\"].apply(lambda row: feature_polarity(row))\n",
    "print(subjectivity.dropna())\n",
    "print(polarity.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f3a1258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        14\n",
       "1         1\n",
       "2        15\n",
       "3         3\n",
       "4         5\n",
       "         ..\n",
       "53194     4\n",
       "53195     1\n",
       "53196     3\n",
       "53197     5\n",
       "53198     1\n",
       "Name: Text, Length: 52210, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_most_common_word = df[\"Text\"].apply(lambda row: feature_freq_most_common_word(row))\n",
    "freq_most_common_word.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3a8043a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         NN\n",
       "1        NNP\n",
       "2         NN\n",
       "3         NN\n",
       "4         NN\n",
       "        ... \n",
       "53194     NN\n",
       "53195    WDT\n",
       "53196     NN\n",
       "53197     VB\n",
       "53198     JJ\n",
       "Name: Text, Length: 52210, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = df[\"Text\"].apply(lambda row: feature_most_pos(row))\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "efa06ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         NN\n",
       "1        NNP\n",
       "2         NN\n",
       "3         NN\n",
       "4         NN\n",
       "        ... \n",
       "53194     NN\n",
       "53195    WDT\n",
       "53196     NN\n",
       "53197     VB\n",
       "53198     JJ\n",
       "Name: Text, Length: 52210, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "489c033f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           .\n",
       "1           .\n",
       "2           .\n",
       "3           ,\n",
       "4           .\n",
       "         ... \n",
       "53194       ?\n",
       "53195       .\n",
       "53196       .\n",
       "53197       ?\n",
       "53198    None\n",
       "Name: Text, Length: 52210, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_punc = df[\"Text\"].apply(lambda row: feature_ending_punctuation(row))\n",
    "last_punc.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5ef957e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           .\n",
       "1           .\n",
       "2           .\n",
       "3           ,\n",
       "4           .\n",
       "         ... \n",
       "53194       ?\n",
       "53195       .\n",
       "53196       .\n",
       "53197       .\n",
       "53198    None\n",
       "Name: Text, Length: 52210, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_punc = df[\"Text\"].apply(lambda row: feature_most_used_punctuation(row))\n",
    "freq_punc.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d1bddfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        4.250000\n",
       "1        4.000000\n",
       "2        4.304933\n",
       "3        3.902439\n",
       "4        4.061224\n",
       "           ...   \n",
       "53194    3.920000\n",
       "53195    4.600000\n",
       "53196    3.382353\n",
       "53197    3.274510\n",
       "53198    4.000000\n",
       "Name: Text, Length: 52210, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_len = df[\"Text\"].apply(lambda row: avg_length(row))\n",
    "avg_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4c2c4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        56.291667\n",
       "1         5.500000\n",
       "2        61.268293\n",
       "3        57.250000\n",
       "4        64.750000\n",
       "           ...    \n",
       "53194    42.333333\n",
       "53195    10.333333\n",
       "53196    52.333333\n",
       "53197    28.625000\n",
       "53198    13.000000\n",
       "Name: Text, Length: 52210, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_sent_len = df[\"Text\"].apply(lambda row: avg_sentence_length(row))\n",
    "avg_sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da98916a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.475410\n",
       "1        0.500000\n",
       "2        0.403587\n",
       "3        0.487805\n",
       "4        0.438776\n",
       "           ...   \n",
       "53194    0.560000\n",
       "53195    0.200000\n",
       "53196    0.617647\n",
       "53197    0.607843\n",
       "53198    0.000000\n",
       "Name: Text, Length: 52210, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_word_ratio = df[\"Text\"].apply(lambda row: feature_short_word_ratio(row))\n",
    "short_word_ratio.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "906b8def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        30\n",
       "1         1\n",
       "2        60\n",
       "3         9\n",
       "4        11\n",
       "         ..\n",
       "53194     3\n",
       "53195     2\n",
       "53196     3\n",
       "53197     9\n",
       "53198     0\n",
       "Name: Text, Length: 52210, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punc_freq = df[\"Text\"].apply(lambda row: punctuation_frequency(row))\n",
    "punc_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56307d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           :\n",
       "1        None\n",
       "2        None\n",
       "3           :\n",
       "4        None\n",
       "         ... \n",
       "53194    None\n",
       "53195    None\n",
       "53196    None\n",
       "53197    None\n",
       "53198    None\n",
       "Name: Text, Length: 52210, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punc_greet = df[\"Text\"].apply(lambda row: punctuation_greeting(row))\n",
    "punc_greet.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0336de00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        247\n",
       "1          2\n",
       "2        456\n",
       "3         42\n",
       "4        100\n",
       "        ... \n",
       "53194     25\n",
       "53195      5\n",
       "53196     34\n",
       "53197     52\n",
       "53198      2\n",
       "Name: Text, Length: 52210, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_words = df[\"Text\"].apply(lambda row: feature_number_words(row))\n",
    "number_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "06450f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        0\n",
      "2        6\n",
      "3        3\n",
      "4        0\n",
      "        ..\n",
      "53194    0\n",
      "53195    0\n",
      "53196    0\n",
      "53197    0\n",
      "53198    0\n",
      "Name: Text, Length: 52210, dtype: int64\n",
      "0           $\n",
      "1        None\n",
      "2           $\n",
      "3           %\n",
      "4        None\n",
      "         ... \n",
      "53194    None\n",
      "53195    None\n",
      "53196    None\n",
      "53197    None\n",
      "53198    None\n",
      "Name: Text, Length: 52210, dtype: object\n",
      "0        1\n",
      "1        0\n",
      "2        6\n",
      "3        2\n",
      "4        0\n",
      "        ..\n",
      "53194    0\n",
      "53195    0\n",
      "53196    0\n",
      "53197    0\n",
      "53198    0\n",
      "Name: Text, Length: 52210, dtype: object\n",
      "0        False\n",
      "1         True\n",
      "2        False\n",
      "3        False\n",
      "4        False\n",
      "         ...  \n",
      "53194    False\n",
      "53195    False\n",
      "53196    False\n",
      "53197    False\n",
      "53198     True\n",
      "Name: Text, Length: 52210, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "number_special_characters = df[\"Text\"].apply(lambda row: feature_number_special_characters(row))\n",
    "print(number_special_characters.dropna())\n",
    "max_special_character = df[\"Text\"].apply(lambda row: feature_max_special_character(row))\n",
    "print(max_special_character.dropna())\n",
    "freq_max_special_character = df[\"Text\"].apply(lambda row: feature_freq_max_special_character(row))\n",
    "print(freq_max_special_character.dropna())\n",
    "\n",
    "single_sentence = df[\"Text\"].apply(lambda row: check_single_sentence(row))\n",
    "print(single_sentence.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "33d3a227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text      Hey:\\nHaven't had the best of months.  Like yo...\n",
       "File                                                   36.0\n",
       "Folder                                             arnold-j\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, [\"Text\", \"File\", \"Folder\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ee8b22",
   "metadata": {},
   "source": [
    "Here we are appending all the extracted features into the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b3b8e21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Folder</th>\n",
       "      <th>File</th>\n",
       "      <th>Message ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Raw Text</th>\n",
       "      <th>Email Length</th>\n",
       "      <th>Digit Density</th>\n",
       "      <th>Space Density</th>\n",
       "      <th>Number of Paragraphs</th>\n",
       "      <th>...</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Most Common POS</th>\n",
       "      <th>Single Sentence</th>\n",
       "      <th>Greeting</th>\n",
       "      <th>Most Common Word</th>\n",
       "      <th>Freq Most Common Word</th>\n",
       "      <th>Total Special Character Count</th>\n",
       "      <th>Max Occurring Special Char</th>\n",
       "      <th>Count of Max Special Char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>arnold-j</td>\n",
       "      <td>36.0</td>\n",
       "      <td>33491127.1075857594966.</td>\n",
       "      <td>Hey:\\nHaven't had the best of months.  Like yo...</td>\n",
       "      <td>Message-ID: &lt;33491127.1075857594966.JavaMail.e...</td>\n",
       "      <td>1046</td>\n",
       "      <td>0.009560</td>\n",
       "      <td>0.278203</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493526</td>\n",
       "      <td>0.135994</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>Hey</td>\n",
       "      <td>the</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>$</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John</td>\n",
       "      <td>arnold-j</td>\n",
       "      <td>667.0</td>\n",
       "      <td>6384662.1075857656041.</td>\n",
       "      <td>Thank you.\\n\\n</td>\n",
       "      <td>Message-ID: &lt;6384662.1075857656041.JavaMail.ev...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NNP</td>\n",
       "      <td>True</td>\n",
       "      <td>Thank</td>\n",
       "      <td>Thank</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John</td>\n",
       "      <td>arnold-j</td>\n",
       "      <td>759.0</td>\n",
       "      <td>21884118.1075857658063.</td>\n",
       "      <td>a couple of observations from here:\\ncash/futu...</td>\n",
       "      <td>Message-ID: &lt;21884118.1075857658063.JavaMail.e...</td>\n",
       "      <td>1955</td>\n",
       "      <td>0.009719</td>\n",
       "      <td>0.267519</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423773</td>\n",
       "      <td>0.019855</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>a</td>\n",
       "      <td>the</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>$</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John</td>\n",
       "      <td>arnold-j</td>\n",
       "      <td>313.0</td>\n",
       "      <td>11352651.1075857600972.</td>\n",
       "      <td>Frank:\\nThe $5,000,000 extra VAR disappears in...</td>\n",
       "      <td>Message-ID: &lt;11352651.1075857600972.JavaMail.e...</td>\n",
       "      <td>172</td>\n",
       "      <td>0.075581</td>\n",
       "      <td>0.267442</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>Frank</td>\n",
       "      <td>the</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>%</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John</td>\n",
       "      <td>arnold-j</td>\n",
       "      <td>710.0</td>\n",
       "      <td>25732708.1075857656969.</td>\n",
       "      <td>don't care about the front.  i think its vulne...</td>\n",
       "      <td>Message-ID: &lt;25732708.1075857656969.JavaMail.e...</td>\n",
       "      <td>400</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402626</td>\n",
       "      <td>-0.008687</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>don</td>\n",
       "      <td>to</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53194</th>\n",
       "      <td>Matthew</td>\n",
       "      <td>lenhart-m</td>\n",
       "      <td>226.0</td>\n",
       "      <td>14926455.1075845207288.</td>\n",
       "      <td>are you going out this weekend?  i think you s...</td>\n",
       "      <td>Message-ID: &lt;14926455.1075845207288.JavaMail.e...</td>\n",
       "      <td>98</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.295918</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>are</td>\n",
       "      <td>you</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53195</th>\n",
       "      <td>Lenhart, Matthew</td>\n",
       "      <td>lenhart-m</td>\n",
       "      <td>318.0</td>\n",
       "      <td>9871308.1075845209613.</td>\n",
       "      <td>whatever.  ride would be good.\\n\\n</td>\n",
       "      <td>Message-ID: &lt;9871308.1075845209613.JavaMail.ev...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>WDT</td>\n",
       "      <td>False</td>\n",
       "      <td>whatever</td>\n",
       "      <td>whatever</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53196</th>\n",
       "      <td>Lenhart, Matthew</td>\n",
       "      <td>lenhart-m</td>\n",
       "      <td>752.0</td>\n",
       "      <td>9553008.1075862009396.</td>\n",
       "      <td>we are meeting these people sunday morning at ...</td>\n",
       "      <td>Message-ID: &lt;9553008.1075862009396.JavaMail.ev...</td>\n",
       "      <td>119</td>\n",
       "      <td>0.067227</td>\n",
       "      <td>0.310924</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>we</td>\n",
       "      <td>at</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53197</th>\n",
       "      <td>Lenhart, Matthew</td>\n",
       "      <td>lenhart-m</td>\n",
       "      <td>351.0</td>\n",
       "      <td>5044717.1075845210498.</td>\n",
       "      <td>i forgot you had a wedding.  i don't go up to ...</td>\n",
       "      <td>Message-ID: &lt;5044717.1075845210498.JavaMail.ev...</td>\n",
       "      <td>168</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.351190</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506944</td>\n",
       "      <td>0.198611</td>\n",
       "      <td>VB</td>\n",
       "      <td>False</td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53198</th>\n",
       "      <td>Lenhart, Matthew</td>\n",
       "      <td>lenhart-m</td>\n",
       "      <td>625.0</td>\n",
       "      <td>32556957.1075854981149.</td>\n",
       "      <td>lisa lisa- \\n\\n</td>\n",
       "      <td>Message-ID: &lt;32556957.1075854981149.JavaMail.e...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>JJ</td>\n",
       "      <td>True</td>\n",
       "      <td>lisa</td>\n",
       "      <td>lisa</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52210 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Author     Folder   File               Message ID  \\\n",
       "0                  John   arnold-j   36.0  33491127.1075857594966.   \n",
       "1                  John   arnold-j  667.0   6384662.1075857656041.   \n",
       "2                  John   arnold-j  759.0  21884118.1075857658063.   \n",
       "3                  John   arnold-j  313.0  11352651.1075857600972.   \n",
       "4                  John   arnold-j  710.0  25732708.1075857656969.   \n",
       "...                 ...        ...    ...                      ...   \n",
       "53194           Matthew  lenhart-m  226.0  14926455.1075845207288.   \n",
       "53195  Lenhart, Matthew  lenhart-m  318.0   9871308.1075845209613.   \n",
       "53196  Lenhart, Matthew  lenhart-m  752.0   9553008.1075862009396.   \n",
       "53197  Lenhart, Matthew  lenhart-m  351.0   5044717.1075845210498.   \n",
       "53198  Lenhart, Matthew  lenhart-m  625.0  32556957.1075854981149.   \n",
       "\n",
       "                                                    Text  \\\n",
       "0      Hey:\\nHaven't had the best of months.  Like yo...   \n",
       "1                                         Thank you.\\n\\n   \n",
       "2      a couple of observations from here:\\ncash/futu...   \n",
       "3      Frank:\\nThe $5,000,000 extra VAR disappears in...   \n",
       "4      don't care about the front.  i think its vulne...   \n",
       "...                                                  ...   \n",
       "53194  are you going out this weekend?  i think you s...   \n",
       "53195                whatever.  ride would be good.\\n\\n    \n",
       "53196  we are meeting these people sunday morning at ...   \n",
       "53197  i forgot you had a wedding.  i don't go up to ...   \n",
       "53198                                    lisa lisa- \\n\\n   \n",
       "\n",
       "                                                Raw Text  Email Length  \\\n",
       "0      Message-ID: <33491127.1075857594966.JavaMail.e...          1046   \n",
       "1      Message-ID: <6384662.1075857656041.JavaMail.ev...             8   \n",
       "2      Message-ID: <21884118.1075857658063.JavaMail.e...          1955   \n",
       "3      Message-ID: <11352651.1075857600972.JavaMail.e...           172   \n",
       "4      Message-ID: <25732708.1075857656969.JavaMail.e...           400   \n",
       "...                                                  ...           ...   \n",
       "53194  Message-ID: <14926455.1075845207288.JavaMail.e...            98   \n",
       "53195  Message-ID: <9871308.1075845209613.JavaMail.ev...            23   \n",
       "53196  Message-ID: <9553008.1075862009396.JavaMail.ev...           119   \n",
       "53197  Message-ID: <5044717.1075845210498.JavaMail.ev...           168   \n",
       "53198  Message-ID: <32556957.1075854981149.JavaMail.e...             8   \n",
       "\n",
       "       Digit Density  Space Density  Number of Paragraphs  ...  Subjectivity  \\\n",
       "0           0.009560       0.278203                   1.0  ...      0.493526   \n",
       "1           0.000000       0.375000                   1.0  ...      0.000000   \n",
       "2           0.009719       0.267519                   3.0  ...      0.423773   \n",
       "3           0.075581       0.267442                   1.0  ...      0.100000   \n",
       "4           0.010000       0.282500                   1.0  ...      0.402626   \n",
       "...              ...            ...                   ...  ...           ...   \n",
       "53194       0.000000       0.295918                   1.0  ...      0.000000   \n",
       "53195       0.000000       0.347826                   1.0  ...      0.600000   \n",
       "53196       0.067227       0.310924                   1.0  ...      0.000000   \n",
       "53197       0.005952       0.351190                   1.0  ...      0.506944   \n",
       "53198       0.000000       0.500000                   1.0  ...      0.000000   \n",
       "\n",
       "       Polarity Most Common POS Single Sentence  Greeting  Most Common Word  \\\n",
       "0      0.135994              NN           False       Hey               the   \n",
       "1      0.000000             NNP            True     Thank             Thank   \n",
       "2      0.019855              NN           False         a               the   \n",
       "3      0.066667              NN           False     Frank               the   \n",
       "4     -0.008687              NN           False       don                to   \n",
       "...         ...             ...             ...       ...               ...   \n",
       "53194  0.000000              NN           False       are               you   \n",
       "53195  0.700000             WDT           False  whatever          whatever   \n",
       "53196  0.000000              NN           False        we                at   \n",
       "53197  0.198611              VB           False         i                 i   \n",
       "53198  0.000000              JJ            True      lisa              lisa   \n",
       "\n",
       "       Freq Most Common Word  Total Special Character Count  \\\n",
       "0                         14                              1   \n",
       "1                          1                              0   \n",
       "2                         15                              6   \n",
       "3                          3                              3   \n",
       "4                          5                              0   \n",
       "...                      ...                            ...   \n",
       "53194                      4                              0   \n",
       "53195                      1                              0   \n",
       "53196                      3                              0   \n",
       "53197                      5                              0   \n",
       "53198                      1                              0   \n",
       "\n",
       "      Max Occurring Special Char  Count of Max Special Char  \n",
       "0                              $                          1  \n",
       "1                           None                          0  \n",
       "2                              $                          6  \n",
       "3                              %                          2  \n",
       "4                           None                          0  \n",
       "...                          ...                        ...  \n",
       "53194                       None                          0  \n",
       "53195                       None                          0  \n",
       "53196                       None                          0  \n",
       "53197                       None                          0  \n",
       "53198                       None                          0  \n",
       "\n",
       "[52210 rows x 30 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combine everything into one dataset\n",
    "\n",
    "df[\"Email Length\"] = email_length\n",
    "df[\"Digit Density\"] = digit_density\n",
    "df[\"Space Density\"] = space_density\n",
    "df[\"Number of Paragraphs\"] = number_paragraphs\n",
    "df[\"Average Sentences per Paragraph\"] = average_sentences_paragraph\n",
    "df[\"Farewell Words\"] = farewell_words\n",
    "df[\"Freq Punc\"] = freq_punc\n",
    "df[\"Last Punc\"] = last_punc\n",
    "df[\"Average Word Length\"] = avg_len\n",
    "df[\"Average Sentence Length\"] = avg_sent_len\n",
    "df[\"Short Word Ratio\"] = short_word_ratio\n",
    "df[\"Punc Frequency\"] = punc_freq\n",
    "df[\"Punc after Greeting\"] = punc_greet\n",
    "df[\"Number Words\"] = number_words\n",
    "df[\"Subjectivity\"] = subjectivity\n",
    "df[\"Polarity\"] = polarity\n",
    "df[\"Most Common POS\"] = pos\n",
    "df[\"Single Sentence\"] = single_sentence\n",
    "df[\"Greeting\"] = greeting_words\n",
    "df[\"Most Common Word\"] = most_common_word\n",
    "df[\"Freq Most Common Word\"] = freq_most_common_word\n",
    "df[\"Total Special Character Count\"] = number_special_characters\n",
    "df[\"Max Occurring Special Char\"] = max_special_character\n",
    "df[\"Count of Max Special Char\"] = freq_max_special_character\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "288840a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Enron_29_Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c189e60e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
